{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d377594",
   "metadata": {},
   "source": [
    "# üéµ Audio Fundamentals for Machine Learning\n",
    "\n",
    "Welcome to the Audio ML Learning Journey! This notebook will teach you the fundamentals of working with audio data for machine learning applications.\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "- **Audio Signal Basics**: Understanding digital audio and sound waves\n",
    "- **Time vs Frequency Domain**: How to analyze audio in different domains\n",
    "- **Audio Processing**: Loading, visualizing, and manipulating audio data\n",
    "- **Practical Applications**: Real-world examples and interactive experiments\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you'll be able to:\n",
    "1. Load and visualize audio files\n",
    "2. Understand the difference between time and frequency domain representations\n",
    "3. Apply basic audio processing techniques\n",
    "4. Create meaningful audio visualizations\n",
    "5. Prepare audio data for machine learning\n",
    "\n",
    "Let's begin our audio adventure! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8046f25b",
   "metadata": {},
   "source": [
    "## üì¶ Import Required Libraries\n",
    "\n",
    "First, let's import all the libraries we'll need for our audio processing journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9e9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries for numerical computing and data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Audio processing libraries\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Visualization libraries\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# System libraries\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Add our custom modules to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our custom audio processing modules\n",
    "try:\n",
    "    from audio_processing import AudioProcessor, create_synthetic_audio\n",
    "    from feature_extraction import FeatureExtractor, AudioFeatureExtractor\n",
    "    from visualization import AudioVisualizer\n",
    "    print(\"‚úÖ Successfully imported custom audio modules!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Could not import custom modules: {e}\")\n",
    "    print(\"Please ensure you're running this notebook from the notebooks/ directory\")\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üéµ All libraries imported successfully!\")\n",
    "print(f\"   NumPy version: {np.__version__}\")\n",
    "print(f\"   Librosa version: {librosa.__version__}\")\n",
    "print(f\"   TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c565ac0",
   "metadata": {},
   "source": [
    "## üåä Understanding Audio Signals\n",
    "\n",
    "### What is Sound?\n",
    "\n",
    "Sound is a **pressure wave** that travels through air (or other media). When we digitize sound:\n",
    "\n",
    "- **Sampling Rate**: How many times per second we measure the wave (Hz)\n",
    "- **Amplitude**: The strength/loudness of the sound\n",
    "- **Frequency**: How fast the wave oscillates (pitch)\n",
    "\n",
    "Let's create some synthetic audio to understand these concepts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243083f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different types of synthetic audio signals\n",
    "\n",
    "duration = 2.0  # seconds\n",
    "sample_rate = 22050  # samples per second\n",
    "\n",
    "print(\"üéº Creating synthetic audio signals...\")\n",
    "\n",
    "# 1. Pure sine wave (musical note A4 = 440 Hz)\n",
    "sine_wave = create_synthetic_audio(duration, sample_rate, frequency=440, wave_type='sine')\n",
    "\n",
    "# 2. Square wave (more harmonic content)\n",
    "square_wave = create_synthetic_audio(duration, sample_rate, frequency=440, wave_type='square')\n",
    "\n",
    "# 3. Sawtooth wave (rich harmonics)\n",
    "sawtooth_wave = create_synthetic_audio(duration, sample_rate, frequency=440, wave_type='sawtooth')\n",
    "\n",
    "# 4. White noise (random)\n",
    "noise = create_synthetic_audio(duration, sample_rate, frequency=440, wave_type='noise')\n",
    "\n",
    "# Create time axis for plotting\n",
    "time_axis = np.linspace(0, duration, len(sine_wave))\n",
    "\n",
    "print(f\"‚úÖ Created {len(sine_wave):,} samples for each signal\")\n",
    "print(f\"   Duration: {duration} seconds\")\n",
    "print(f\"   Sample rate: {sample_rate:,} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96c2cf1",
   "metadata": {},
   "source": [
    "### üìä Visualizing Audio Waveforms\n",
    "\n",
    "Let's visualize these different types of audio signals to understand their characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae280f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive visualization of different waveforms\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "\n",
    "signals = {\n",
    "    'Sine Wave (Pure Tone)': sine_wave,\n",
    "    'Square Wave (Harmonic Rich)': square_wave, \n",
    "    'Sawtooth Wave (Very Harmonic)': sawtooth_wave,\n",
    "    'White Noise (Random)': noise\n",
    "}\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'purple']\n",
    "\n",
    "for idx, (name, signal) in enumerate(signals.items()):\n",
    "    # Show only first 0.01 seconds for clarity\n",
    "    samples_to_show = int(0.01 * sample_rate)\n",
    "    \n",
    "    axes[idx].plot(time_axis[:samples_to_show], signal[:samples_to_show], \n",
    "                   color=colors[idx], linewidth=1.5, alpha=0.8)\n",
    "    \n",
    "    axes[idx].set_title(f'{name}', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Amplitude')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics\n",
    "    rms = np.sqrt(np.mean(signal**2))\n",
    "    max_amp = np.max(np.abs(signal))\n",
    "    axes[idx].text(0.02, 0.98, f'RMS: {rms:.3f}\\nMax: {max_amp:.3f}', \n",
    "                   transform=axes[idx].transAxes, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "axes[-1].set_xlabel('Time (seconds)')\n",
    "plt.suptitle('Different Types of Audio Waveforms', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üéµ Notice how different waveforms have different shapes and characteristics!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3750204",
   "metadata": {},
   "source": [
    "### üéß Listen to the Audio Signals\n",
    "\n",
    "Let's actually listen to these different signals to hear how they sound:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8909529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéß Listen to different waveform types:\")\n",
    "print(\"\\n1. Sine Wave (Pure tone - sounds like a whistle):\")\n",
    "display(Audio(sine_wave, rate=sample_rate))\n",
    "\n",
    "print(\"\\n2. Square Wave (Harsh, digital sound):\")\n",
    "display(Audio(square_wave, rate=sample_rate))\n",
    "\n",
    "print(\"\\n3. Sawtooth Wave (Buzzy, rich sound):\")\n",
    "display(Audio(sawtooth_wave, rate=sample_rate))\n",
    "\n",
    "print(\"\\n4. White Noise (Static sound):\")\n",
    "display(Audio(noise, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81124d7e",
   "metadata": {},
   "source": [
    "## üîÑ Time Domain vs Frequency Domain\n",
    "\n",
    "### Time Domain\n",
    "Shows how the signal changes over **time** (what we plotted above)\n",
    "\n",
    "### Frequency Domain \n",
    "Shows what **frequencies** are present in the signal (using FFT - Fast Fourier Transform)\n",
    "\n",
    "Let's explore both representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c84b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_and_frequency_domain(signal, signal_name, sample_rate):\n",
    "    \"\"\"Plot both time domain and frequency domain representations.\"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Time domain (first 0.01 seconds)\n",
    "    samples_to_show = int(0.01 * sample_rate)\n",
    "    time_short = np.linspace(0, 0.01, samples_to_show)\n",
    "    \n",
    "    ax1.plot(time_short, signal[:samples_to_show], linewidth=2)\n",
    "    ax1.set_title(f'{signal_name} - Time Domain')\n",
    "    ax1.set_xlabel('Time (seconds)')\n",
    "    ax1.set_ylabel('Amplitude')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Frequency domain (FFT)\n",
    "    fft = np.fft.fft(signal)\n",
    "    freqs = np.fft.fftfreq(len(signal), 1/sample_rate)\n",
    "    \n",
    "    # Only show positive frequencies up to 2000 Hz for clarity\n",
    "    positive_freqs = freqs[:len(freqs)//2]\n",
    "    positive_fft = np.abs(fft[:len(fft)//2])\n",
    "    \n",
    "    freq_mask = positive_freqs <= 2000\n",
    "    \n",
    "    ax2.plot(positive_freqs[freq_mask], positive_fft[freq_mask], linewidth=2)\n",
    "    ax2.set_title(f'{signal_name} - Frequency Domain')\n",
    "    ax2.set_xlabel('Frequency (Hz)')\n",
    "    ax2.set_ylabel('Magnitude')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Analyze each signal\n",
    "signals_to_analyze = [\n",
    "    (sine_wave, \"Sine Wave\"),\n",
    "    (square_wave, \"Square Wave\"),\n",
    "    (sawtooth_wave, \"Sawtooth Wave\"),\n",
    "    (noise, \"White Noise\")\n",
    "]\n",
    "\n",
    "for signal, name in signals_to_analyze:\n",
    "    plot_time_and_frequency_domain(signal, name, sample_rate)\n",
    "    print(f\"\\n{name}: Notice the frequency content!\")\n",
    "    if name == \"Sine Wave\":\n",
    "        print(\"   - Single peak at 440 Hz (pure tone)\")\n",
    "    elif name == \"Square Wave\":\n",
    "        print(\"   - Multiple peaks at odd harmonics (440, 1320, 2200 Hz...)\")\n",
    "    elif name == \"Sawtooth Wave\":\n",
    "        print(\"   - Many harmonics at all multiples of 440 Hz\")\n",
    "    elif name == \"White Noise\":\n",
    "        print(\"   - Energy spread across all frequencies\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605eff8",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Interactive Audio Explorer\n",
    "\n",
    "Let's create an interactive widget to explore how frequency and amplitude affect audio signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b4113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive audio parameter explorer\n",
    "\n",
    "def interactive_audio_explorer(frequency=440, amplitude=0.5, wave_type='sine'):\n",
    "    \"\"\"Interactive function to explore audio parameters.\"\"\"\n",
    "    \n",
    "    # Create audio signal\n",
    "    duration = 1.0\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "    \n",
    "    if wave_type == 'sine':\n",
    "        signal = amplitude * np.sin(2 * np.pi * frequency * t)\n",
    "    elif wave_type == 'square':\n",
    "        signal = amplitude * np.sign(np.sin(2 * np.pi * frequency * t))\n",
    "    elif wave_type == 'sawtooth':\n",
    "        signal = amplitude * 2 * (t * frequency - np.floor(t * frequency + 0.5))\n",
    "    \n",
    "    # Plot time and frequency domain\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Time domain (first 0.02 seconds)\n",
    "    samples_to_show = int(0.02 * sample_rate)\n",
    "    time_short = t[:samples_to_show]\n",
    "    \n",
    "    ax1.plot(time_short, signal[:samples_to_show], linewidth=2, color='blue')\n",
    "    ax1.set_title(f'{wave_type.capitalize()} Wave - {frequency} Hz')\n",
    "    ax1.set_xlabel('Time (seconds)')\n",
    "    ax1.set_ylabel('Amplitude')\n",
    "    ax1.set_ylim(-1, 1)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Frequency domain\n",
    "    fft = np.fft.fft(signal)\n",
    "    freqs = np.fft.fftfreq(len(signal), 1/sample_rate)\n",
    "    positive_freqs = freqs[:len(freqs)//2]\n",
    "    positive_fft = np.abs(fft[:len(fft)//2])\n",
    "    \n",
    "    freq_mask = positive_freqs <= 2000\n",
    "    \n",
    "    ax2.plot(positive_freqs[freq_mask], positive_fft[freq_mask], linewidth=2, color='red')\n",
    "    ax2.set_title('Frequency Spectrum')\n",
    "    ax2.set_xlabel('Frequency (Hz)')\n",
    "    ax2.set_ylabel('Magnitude')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display audio\n",
    "    print(f\"üéµ Playing {wave_type} wave at {frequency} Hz with amplitude {amplitude}\")\n",
    "    display(Audio(signal, rate=sample_rate))\n",
    "\n",
    "# Create interactive widgets\n",
    "frequency_slider = widgets.IntSlider(\n",
    "    value=440, min=100, max=1000, step=10,\n",
    "    description='Frequency (Hz):'\n",
    ")\n",
    "\n",
    "amplitude_slider = widgets.FloatSlider(\n",
    "    value=0.5, min=0.1, max=1.0, step=0.1,\n",
    "    description='Amplitude:'\n",
    ")\n",
    "\n",
    "wave_type_dropdown = widgets.Dropdown(\n",
    "    options=['sine', 'square', 'sawtooth'],\n",
    "    value='sine',\n",
    "    description='Wave Type:'\n",
    ")\n",
    "\n",
    "# Create interactive widget\n",
    "interactive_widget = widgets.interact(\n",
    "    interactive_audio_explorer,\n",
    "    frequency=frequency_slider,\n",
    "    amplitude=amplitude_slider,\n",
    "    wave_type=wave_type_dropdown\n",
    ")\n",
    "\n",
    "print(\"üéõÔ∏è Use the controls above to explore different audio parameters!\")\n",
    "print(\"   - Try different frequencies to hear pitch changes\")\n",
    "print(\"   - Change amplitude to hear volume changes\")\n",
    "print(\"   - Switch wave types to hear timbre differences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94122a2",
   "metadata": {},
   "source": [
    "## üîß Audio Processing with Our Custom Modules\n",
    "\n",
    "Now let's use our custom audio processing modules to explore more advanced concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc177838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our custom audio processor\n",
    "processor = AudioProcessor(sample_rate=22050)\n",
    "visualizer = AudioVisualizer()\n",
    "\n",
    "print(\"üîß Initialized custom audio processing modules\")\n",
    "\n",
    "# Create a more complex audio signal for processing\n",
    "print(\"\\nüéº Creating a complex musical signal...\")\n",
    "\n",
    "duration = 4.0\n",
    "t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "\n",
    "# Create a chord (multiple frequencies)\n",
    "frequencies = [261.63, 329.63, 392.00]  # C major chord (C, E, G)\n",
    "complex_signal = np.zeros_like(t)\n",
    "\n",
    "for i, freq in enumerate(frequencies):\n",
    "    amplitude = 0.3 / (i + 1)  # Decreasing amplitude for each note\n",
    "    complex_signal += amplitude * np.sin(2 * np.pi * freq * t)\n",
    "\n",
    "# Add some amplitude modulation (vibrato effect)\n",
    "modulation = 1 + 0.1 * np.sin(2 * np.pi * 5 * t)  # 5 Hz vibrato\n",
    "complex_signal *= modulation\n",
    "\n",
    "# Add a bit of noise for realism\n",
    "complex_signal += 0.02 * np.random.normal(0, 1, len(complex_signal))\n",
    "\n",
    "print(f\"‚úÖ Created complex signal with {len(frequencies)} frequencies\")\n",
    "\n",
    "# Get signal information\n",
    "info = processor.get_audio_info(complex_signal)\n",
    "print(\"\\nüìä Audio Signal Information:\")\n",
    "for key, value in info.items():\n",
    "    print(f\"   {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b32e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the complex signal\n",
    "print(\"üìä Visualizing the complex musical signal...\")\n",
    "\n",
    "visualizer.plot_waveform(\n",
    "    complex_signal, \n",
    "    sample_rate=sample_rate,\n",
    "    title=\"Complex Musical Signal (C Major Chord with Vibrato)\"\n",
    ")\n",
    "\n",
    "# Let's listen to it\n",
    "print(\"\\nüéß Listen to the complex musical signal:\")\n",
    "display(Audio(complex_signal, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af7a04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spectrogram visualization\n",
    "print(\"üåà Creating spectrogram visualization...\")\n",
    "\n",
    "visualizer.plot_spectrogram(\n",
    "    complex_signal,\n",
    "    sample_rate=sample_rate,\n",
    "    title=\"Spectrogram - Time vs Frequency vs Amplitude\"\n",
    ")\n",
    "\n",
    "print(\"\\nüîç In the spectrogram, you can see:\")\n",
    "print(\"   - Horizontal lines at ~262, 330, and 392 Hz (the chord frequencies)\")\n",
    "print(\"   - Color intensity shows amplitude over time\")\n",
    "print(\"   - Any vibrato would show as slight frequency variations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115bf55",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Audio Segmentation and Processing\n",
    "\n",
    "For machine learning, we often need to break audio into smaller, manageable segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7472d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate audio segmentation\n",
    "print(\"‚úÇÔ∏è Demonstrating audio segmentation...\")\n",
    "\n",
    "# Create segments\n",
    "segment_length = 1.0  # 1 second segments\n",
    "segments = processor.segment_audio(\n",
    "    complex_signal, \n",
    "    segment_length=segment_length,\n",
    "    hop_length=0.5,  # 50% overlap\n",
    "    pad_final=True\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Created {len(segments)} segments from {info['duration']:.2f}s audio\")\n",
    "\n",
    "# Visualize first few segments\n",
    "fig, axes = plt.subplots(min(4, len(segments)), 1, figsize=(12, 8))\n",
    "if len(segments) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i in range(min(4, len(segments))):\n",
    "    segment_time = np.linspace(0, segment_length, len(segments[i]))\n",
    "    axes[i].plot(segment_time, segments[i], linewidth=1, alpha=0.8)\n",
    "    axes[i].set_title(f'Segment {i+1}')\n",
    "    axes[i].set_ylabel('Amplitude')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    if i == len(axes) - 1:\n",
    "        axes[i].set_xlabel('Time (seconds)')\n",
    "\n",
    "plt.suptitle('Audio Segments', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Listen to individual segments\n",
    "print(\"\\nüéß Listen to individual segments:\")\n",
    "for i in range(min(3, len(segments))):\n",
    "    print(f\"\\nSegment {i+1}:\")\n",
    "    display(Audio(segments[i], rate=sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696dc848",
   "metadata": {},
   "source": [
    "## üîÑ Audio Data Augmentation\n",
    "\n",
    "For machine learning, we often need to create variations of our data to improve model robustness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e9634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate data augmentation techniques\n",
    "print(\"üîÑ Demonstrating audio data augmentation...\")\n",
    "\n",
    "# Use first segment for demonstration\n",
    "original_segment = segments[0]\n",
    "\n",
    "# 1. Add noise\n",
    "noisy_audio = processor.add_noise(original_segment, noise_factor=0.05)\n",
    "\n",
    "# 2. Time shift\n",
    "shifted_audio = processor.time_shift(original_segment, shift_samples=1000)\n",
    "\n",
    "# 3. Speed change\n",
    "fast_audio = processor.change_speed(original_segment, speed_factor=1.2)\n",
    "slow_audio = processor.change_speed(original_segment, speed_factor=0.8)\n",
    "\n",
    "# Visualize augmentations\n",
    "augmented_signals = {\n",
    "    'Original': original_segment,\n",
    "    'With Noise': noisy_audio,\n",
    "    'Time Shifted': shifted_audio,\n",
    "    'Faster (1.2x)': fast_audio,\n",
    "    'Slower (0.8x)': slow_audio\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(len(augmented_signals), 1, figsize=(12, 12))\n",
    "\n",
    "for idx, (name, signal) in enumerate(augmented_signals.items()):\n",
    "    # Show first 0.5 seconds for clarity\n",
    "    samples_to_show = int(0.5 * sample_rate)\n",
    "    if len(signal) >= samples_to_show:\n",
    "        time_short = np.linspace(0, 0.5, samples_to_show)\n",
    "        axes[idx].plot(time_short, signal[:samples_to_show], linewidth=1)\n",
    "    else:\n",
    "        time_short = np.linspace(0, len(signal)/sample_rate, len(signal))\n",
    "        axes[idx].plot(time_short, signal, linewidth=1)\n",
    "    \n",
    "    axes[idx].set_title(f'{name}')\n",
    "    axes[idx].set_ylabel('Amplitude')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add RMS value\n",
    "    rms = np.sqrt(np.mean(signal**2))\n",
    "    axes[idx].text(0.02, 0.98, f'RMS: {rms:.3f}', \n",
    "                   transform=axes[idx].transAxes, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "axes[-1].set_xlabel('Time (seconds)')\n",
    "plt.suptitle('Audio Data Augmentation Techniques', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéß Listen to the augmented versions:\")\n",
    "for name, signal in list(augmented_signals.items())[:3]:  # First 3 for brevity\n",
    "    print(f\"\\n{name}:\")\n",
    "    display(Audio(signal, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d28932",
   "metadata": {},
   "source": [
    "## üß† Key Concepts Summary\n",
    "\n",
    "### What We've Learned:\n",
    "\n",
    "1. **Audio Signals**: Digital representations of sound waves\n",
    "2. **Time Domain**: Shows amplitude changes over time\n",
    "3. **Frequency Domain**: Shows what frequencies are present (FFT)\n",
    "4. **Waveform Types**: Sine, square, sawtooth have different harmonic content\n",
    "5. **Audio Processing**: Normalization, segmentation, augmentation\n",
    "6. **Visualization**: Waveforms, spectrograms help understand audio\n",
    "\n",
    "### Why This Matters for ML:\n",
    "\n",
    "- **Feature Extraction**: We need to convert audio to numbers ML can understand\n",
    "- **Data Preparation**: Segmentation creates consistent input sizes\n",
    "- **Augmentation**: Creates more training data and robust models\n",
    "- **Visualization**: Helps debug and understand model behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3679bc80",
   "metadata": {},
   "source": [
    "## üéØ Practice Exercises\n",
    "\n",
    "Try these exercises to reinforce your learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c487e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Create your own musical chord\n",
    "print(\"üéµ Exercise 1: Create Your Own Musical Chord\")\n",
    "print(\"Try creating different chords by changing the frequencies below:\")\n",
    "print()\n",
    "\n",
    "# Define some musical notes (frequencies in Hz)\n",
    "notes = {\n",
    "    'C4': 261.63, 'D4': 293.66, 'E4': 329.63, 'F4': 349.23,\n",
    "    'G4': 392.00, 'A4': 440.00, 'B4': 493.88, 'C5': 523.25\n",
    "}\n",
    "\n",
    "print(\"Available notes:\", list(notes.keys()))\n",
    "print(\"\\nTry creating different chords:\")\n",
    "print(\"- Major chord: C4, E4, G4\")\n",
    "print(\"- Minor chord: C4, D#4 (use 311.13), G4\")\n",
    "print(\"- Sus4 chord: C4, F4, G4\")\n",
    "\n",
    "# TODO: Modify this list to create your own chord!\n",
    "my_chord_notes = ['C4', 'E4', 'G4']  # C Major chord\n",
    "\n",
    "# Create the chord\n",
    "duration = 3.0\n",
    "t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "my_chord = np.zeros_like(t)\n",
    "\n",
    "for note in my_chord_notes:\n",
    "    if note in notes:\n",
    "        freq = notes[note]\n",
    "        my_chord += 0.3 * np.sin(2 * np.pi * freq * t)\n",
    "\n",
    "print(f\"\\nüéº Your chord: {' + '.join(my_chord_notes)}\")\n",
    "display(Audio(my_chord, rate=sample_rate))\n",
    "\n",
    "# Visualize your chord\n",
    "visualizer.plot_waveform(my_chord, sample_rate, title=f\"Your Chord: {' + '.join(my_chord_notes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d123aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Analyze the frequency content of your chord\n",
    "print(\"üîç Exercise 2: Frequency Analysis of Your Chord\")\n",
    "\n",
    "# Create FFT analysis\n",
    "fft = np.fft.fft(my_chord)\n",
    "freqs = np.fft.fftfreq(len(my_chord), 1/sample_rate)\n",
    "positive_freqs = freqs[:len(freqs)//2]\n",
    "positive_fft = np.abs(fft[:len(fft)//2])\n",
    "\n",
    "# Plot frequency spectrum\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(positive_freqs[:len(positive_freqs)//10], positive_fft[:len(positive_fft)//10])\n",
    "plt.title(f'Frequency Spectrum of Your Chord: {\" + \".join(my_chord_notes)}')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Mark expected frequencies\n",
    "for note in my_chord_notes:\n",
    "    if note in notes:\n",
    "        freq = notes[note]\n",
    "        plt.axvline(x=freq, color='red', linestyle='--', alpha=0.7, label=f'{note} ({freq:.1f} Hz)')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Can you identify the peaks corresponding to your chord notes?\")\n",
    "print(\"üéØ Do you see any harmonics (multiples of the fundamental frequencies)?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd70b452",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "Congratulations! You've learned the fundamentals of audio processing for machine learning. \n",
    "\n",
    "### What's Next:\n",
    "\n",
    "1. **Feature Extraction** (Notebook 02): Learn to extract MFCC, spectral, and other ML features\n",
    "2. **Model Training** (Notebook 03): Build and train audio classification models\n",
    "3. **Real-time Processing** (Notebook 04): Apply your knowledge to live audio\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- Audio is just numbers that can be processed mathematically\n",
    "- Time and frequency domains provide different perspectives\n",
    "- Visualization helps understand and debug audio processing\n",
    "- Proper preprocessing is crucial for ML success\n",
    "\n",
    "### Resources for Further Learning:\n",
    "\n",
    "- [Librosa Documentation](https://librosa.org/)\n",
    "- [Digital Signal Processing Basics](https://www.dspguide.com/)\n",
    "- [Audio ML Papers](https://paperswithcode.com/area/audio)\n",
    "\n",
    "Happy audio learning! üéµü§ñ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
